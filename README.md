# Data Analyst Agent ðŸ¤–ðŸ“Š

## Overview
The Data Analyst Agent is an intelligent assistant designed to help users analyze data from various document types. Users can upload files (including text documents, spreadsheets, PDFs, and images), ask questions about their content, request data analysis, and generate visualizations for tabular data. The agent leverages the power of Large Language Models (LLMs) from Together AI, specifically targeting the `meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8` model, with fallbacks to other Llama models for improved reliability.

This project focuses on robust backend processing, intelligent interaction, and demonstrating the capabilities of LLMs in data analysis tasks. The user interface is built using `ipywidgets` within a Jupyter Notebook environment.

## DEMO Images


## Features

*   **Multi-Format File Upload:** Supports `.txt`, `.csv`, `.xlsx` (Excel), `.docx` (Word), `.pdf`, and common image formats (`.png`, `.jpg`, `.jpeg`).
*   **Intelligent Q&A:** Answer questions based on the content of uploaded text documents, PDFs, or OCR'd images.
*   **Tabular Data Analysis:**
    *   Accepts CSV and Excel files.
    *   Generates Python (Pandas, NumPy) code based on user requests to perform data analysis.
    *   Executes the generated code in a controlled environment.
*   **Data Visualization:**
    *   Generates Python (Matplotlib, Seaborn) code to create various plots from tabular data.
    *   Displays generated plots directly in the notebook.
*   **LLM-Powered Interpretation:** After code execution, the LLM interprets the results (stdout, stderr, plots) and explains them in natural language.
*   **Contextual Conversation:** Maintains conversation history to understand follow-up questions.
*   **Robust OCR:**
    *   Advanced image preprocessing (using OpenCV if available, otherwise PIL) to enhance OCR quality.
    *   Iterative OCR attempts with different Tesseract configurations (PSM modes).
    *   Handles image-based PDFs by converting pages to images (using `pdf2image` and Poppler) and then performing OCR.
*   **LLM Fallback Mechanism:** Automatically switches to alternative Llama models if the primary model is rate-limited, improving agent availability.
*   **Dependency Checks:** Includes a utility to check for necessary external dependencies like Tesseract, Poppler, and optional Python packages.

## Project Structure

data-analyst-agent/
â”œâ”€â”€ main_notebook.ipynb # Main application logic and UI (using ipywidgets)
â”œâ”€â”€ .env.example # Example environment file (rename to .env)
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ uploads/ # Temporary storage for user-uploaded files (gitignored)
â”œâ”€â”€ outputs/ # Stores generated outputs like plots (gitignored)
â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ file_parser.py # Handles parsing of all supported file types
â”‚ â”œâ”€â”€ llm_handler.py # Manages interactions with the Together AI LLM
â”‚ â””â”€â”€ code_executor.py # Executes Python code generated by the LLM
â””â”€â”€ README.md # This file


## Technical Stack

*   **Language:** Python 3.x
*   **Core Libraries:**
    *   `ipywidgets`: For the Jupyter Notebook UI.
    *   `pandas`: For data manipulation.
    *   `numpy`: For numerical operations.
    *   `matplotlib`, `seaborn`: For data visualization.
    *   `python-docx`: For reading `.docx` files.
    *   `PyPDF2`: For basic text extraction from `.pdf` files.
    *   `Pillow (PIL)`: For image processing.
    *   `pytesseract`: For Optical Character Recognition (OCR).
    *   `pdf2image`: For converting PDF pages to images (for OCR).
    *   `opencv-python` (optional, recommended): For advanced image preprocessing for OCR.
    *   `together-python`: Official Together AI Python client.
    *   `python-dotenv`: For managing environment variables.
*   **External Dependencies:**
    *   **Tesseract OCR Engine:** Required for `pytesseract`.
    *   **Poppler:** Required by `pdf2image` for PDF-to-image conversion.
*   **LLM Provider:** [Together AI](https://www.together.ai/)
*   **Primary LLM:** `meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8`

## Setup and Installation

### 1. Prerequisites

*   Python 3.8 or higher.
*   `pip` (Python package installer).
*   **Tesseract OCR Engine:**
    *   **Windows:** Download and install from [UB Mannheim Tesseract GitHub](https://github.com/UB-Mannheim/tesseract/wiki). During installation, ensure you select additional language data if needed (English is usually included) and **add Tesseract to your system PATH**.
    *   **macOS:** `brew install tesseract tesseract-lang`
    *   **Linux (Debian/Ubuntu):** `sudo apt-get install tesseract-ocr libtesseract-dev tesseract-ocr-eng`
*   **Poppler (for PDF OCR):**
    *   **Windows:**
        1.  Download Poppler binaries for Windows (e.g., from [thi s recommended link](https://github.com/oschwartz10612/poppler-windows/releases/)).
        2.  Extract the archive (e.g., to `C:\poppler`).
        3.  Add the `bin\` directory within your Poppler installation (e.g., `C:\poppler\poppler-X.Y.Z\bin`) to your system PATH.
    *   **macOS:** `brew install poppler`
    *   **Linux (Debian/Ubuntu):** `sudo apt-get install poppler-utils`

### 2. Clone the Repository (if applicable)

```bash
git clone <your-repository-url>
cd data-analyst-agent

3. Create a Virtual Environment (Recommended)
python -m venv venv
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate

4. Install Python Dependencies
pip install -r requirements.txt

The requirements.txt should include:
notebook
ipywidgets
pandas
openpyxl
python-docx
PyPDF2
Pillow
pytesseract
pdf2image
opencv-python  # Optional but highly recommended for better OCR
together
python-dotenv
matplotlib
seaborn

5. Set Up Environment Variables
Sign up for an account at Together AI to get an API key.
Rename the .env.example file to .env.
Open the .env file and add your Together AI API key:
TOGETHER_API_KEY="your_together_ai_api_key_here"


6. Configure Tesseract Path in file_parser.py (Important!)
Open utils/file_parser.py. Even if Tesseract is in your PATH, it's robust to explicitly set the command path for pytesseract.
Find the line (it's already there in your provided code):
# Configure Tesseract path if necessary (especially on Windows)
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

Usage
 1.Upload a File: Click the "Upload File" button and select a supported document. A preview of the content will be displayed.
 2.Ask a Query: Type your question or analysis request related to the uploaded file in the "Your Query" text area.
 3.Submit: Click "Submit Query".
  The agent will process your request.
  If it's a Q&A, it will provide a textual answer.
  If it's a data analysis/visualization task, it will:
  Display the Python code it generated.
  Show the output of the code (text or plots).
  Provide a natural language interpretation of the results.
4. Follow-up: Ask follow-up questions. The agent maintains conversation context.
5. Clear Conversation: Click "Clear Conversation" to reset the agent and start fresh.
